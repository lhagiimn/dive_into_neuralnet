{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e77c80be-9332-43fe-aabd-54d0ade370b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed2e6b0-4824-4f9f-9035-3b00b3666d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Problem 1] Creating a one-dimensional convolutional layer class that limits the number of channels to one\n",
    "\n",
    "\n",
    "class Conv1D:\n",
    "  \n",
    "  def forward_propagate(self, x, w, b):\n",
    "    # Output value (which will converted to np.array)\n",
    "    a = []\n",
    "    for i in range(len(w)-1):\n",
    "      a.append(np.matmul(x[i:i+len(w)], w) + b[0])\n",
    "\n",
    "    return np.array(a)\n",
    "\n",
    "  def backward_propagate(self, x, w, da):\n",
    "    \"\"\"\n",
    "    The backward propagate intends to find three factors:\n",
    "    dw, db and dx\n",
    "\n",
    "    dw, db: \n",
    "      Using the formula similar to DNN model\n",
    "\n",
    "    dx:\n",
    "      Using the weight value multiply with the derivative of activate function da\n",
    "\n",
    "    \"\"\"\n",
    "    # Calculate db\n",
    "    db = np.sum(da)\n",
    "\n",
    "    # Calculate dw\n",
    "    dw = []\n",
    "    for i in range(len(w)):\n",
    "      dw.append(np.matmul(da, x[i:i+len(da)]))\n",
    "    dw = np.array(dw)\n",
    "\n",
    "    # Calculate dx\n",
    "    dx = []\n",
    "    # Adding all the shared errors\n",
    "    # The errors lies in the two heads of array (j - s < 0) and (j - s > N - 1)\n",
    "    new_w = np.insert(w[::-1], 0, 0) # Reverse the weight array\n",
    "    new_w = np.append(new_w, 0)\n",
    "    for i in range(len(new_w) - 1):\n",
    "      dx.append(np.matmul(da, new_w[i:i+len(da)]))\n",
    "    dx = np.array(dx[::-1]) # Reverse again\n",
    "\n",
    "    return dw, db, dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db19375a-50c4-4fd3-998c-716d53622e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Problem 2] Output size calculation after one-dimensional convolution\n",
    "\n",
    "def output_size_calculation(n_in, F, P=0, S=1):\n",
    "  n_out = int((n_in + 2*P - F)/S + 1)\n",
    "  return n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "005cf581-cedf-472f-a061-a2a4bcca2206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward:  [35 50]\n",
      "dw:  [ 50  80 110]\n",
      "db:  30\n",
      "dx:  [ 30 110 170 140]\n"
     ]
    }
   ],
   "source": [
    "#[Problem 3] Experiment of one-dimensional convolutional layer with small array\n",
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])\n",
    "da = np.array([10, 20])\n",
    "\n",
    "\n",
    "Conv1D_model = Conv1D()\n",
    "dw, db, dx = Conv1D_model.backward_propagate(x, w, da)\n",
    "\n",
    "print(\"Forward: \", Conv1D_model.forward_propagate(x, w, b))\n",
    "print(\"dw: \", dw)\n",
    "print(\"db: \", db)\n",
    "print(\"dx: \", dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "713fe026-9672-4101-8383-a289aa87ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Problem 4] Creating a one-dimensional convolutional layer class that does not limit the number of channels\n",
    "x = np.ones((28, 28))\n",
    "y = np.pad(x, pad_width=((0,0), (2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1136618f-b164-4bba-a6f1-e155ed6cb264",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1DFull:\n",
    "  \n",
    "  def __init__(self, filter_size, initializer, optimizer, channels_in = 1, channels_out = 1, pad=0):\n",
    "    self.filter_size = filter_size\n",
    "    self.optimizier = optimizer\n",
    "    self.channels_in = channels_in\n",
    "    self.channels_out = channels_out\n",
    "    self.n_out = None\n",
    "    self.pad = pad\n",
    "    self.W = initializer.W(channels_out, channels_in, filter_size)\n",
    "    self.B = initializer.B(channels_out)\n",
    "\n",
    "  def forward_propagate(self, X):\n",
    "    self.n_in = X.shape[-1]\n",
    "    self.n_out = output_size_calculation(self.n_in, self.filter_size, self.pad)\n",
    "\n",
    "    X = X.reshape(self.channels_in, self.n_in)\n",
    "    self.X = np.pad(X, ((0,0), ((self.filter_size-1), 0)))\n",
    "    self.X1 = np.zeros((self.channels_in, self.filter_size, self.n_in + (self.filter_size - 1)))\n",
    "\n",
    "    for i in range(self.filter_size):\n",
    "      self.X1[:, i] = np.roll(self.X, -i , axis=1)\n",
    "\n",
    "    A = np.sum(self.X1[:, :, self.filter_size -1 - self.pad:self.n_in + self.pad]*self.W[:, :, :, np.newaxis], axis=(1,2)) + self.B.reshape(-1, 1)\n",
    "\n",
    "    return A\n",
    "\n",
    "  def backward_propagate(self, dA):\n",
    "    \n",
    "    self.dW = np.sum(np.dot(dA, self.X1[:, :, self.filter_size - 1 - self.pad:self.n_in + self.pad, np.newaxis]), axis=-1)\n",
    "    self.dB = np.sum(dA, axis=1)\n",
    "    self.dA = np.pad(dA, ((0,0), (0, (self.filter_size - 1))))\n",
    "    self.dA1 = np.zeros((self.channels_out, self.filter_size, self.dA.shape[-1]))\n",
    "\n",
    "    for i in range(self.filter_size):\n",
    "      self.dA1[:, i] = np.roll(self.dA, i , axis=1)\n",
    "\n",
    "    dX = np.sum(np.matmul(self.W, self.dA1), axis=0)\n",
    "    self.optimizer.update(self)\n",
    "\n",
    "    return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "904c1678-693b-4504-8ff1-9e3f451796a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightInitializer:\n",
    "    def __init__(self, gamma=1.0):\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def initialize_weights(self, shape):\n",
    "        std_dev = np.sqrt(self.gamma / np.prod(shape[:-1]))\n",
    "        return np.random.normal(loc=0, scale=std_dev, size=shape)\n",
    "\n",
    "    def initialize_biases(self, shape):\n",
    "        return np.zeros(shape)\n",
    "\n",
    "    def W(self, channels_out, channels_in, filter_size):\n",
    "        # Initialize weights and biases separately\n",
    "        self.W = self.initialize_weights((channels_out, channels_in, filter_size))\n",
    "       \n",
    "    def B(self, channels_out):\n",
    "        self.B = self.initialize_biases((channels_out,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fd35ffe-1a6f-4679-97cd-34776f3ed8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SGD:\n",
    "    def __init__(self, lr):\n",
    "      self.lr = lr\n",
    "    \n",
    "    def update(self, layer):\n",
    "      layer.W -= self.lr * layer.dW\n",
    "      layer.B -= self.lr * layer.dB\n",
    "      return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "886ab415-d6be-4ded-8979-a05f37461e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = Conv1DFull(filter_size=3, initializer=WeightInitializer(0.01), optimizer=SGD(0.01), channels_in=2, channels_out=3, pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02373a73-cc95-40b9-b45c-372e84d68b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]])\n",
    "\n",
    "# Array shapes: (channels_in, channels_out, filter_size)\n",
    "conv_model.W = np.ones((3,2,3), dtype=float)\n",
    "conv_model.b = np.array([1,2,3], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2599a09e-cd6e-400d-9b1f-9e876d6ecade",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m conv_test \u001b[38;5;241m=\u001b[39m \u001b[43mconv_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_propagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults of forward \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, conv_test)\n",
      "Cell \u001b[1;32mIn[6], line 24\u001b[0m, in \u001b[0;36mConv1DFull.forward_propagate\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_size):\n\u001b[0;32m     22\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX1[:, i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mroll(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX, \u001b[38;5;241m-\u001b[39mi , axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m A \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX1[:, :, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_size \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_in \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW[:, :, :, np\u001b[38;5;241m.\u001b[39mnewaxis], axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m A\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "\n",
    "conv_test = conv_model.forward_propagate(x)\n",
    "print(\"Results of forward \\n\", conv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041f60d5-5053-4a8a-91a4-7b77b7dfe7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
